{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages we'll use\n",
    "\n",
    "import numpy as np\n",
    "import os, glob, csv\n",
    "\n",
    "# librosa is a widely-used audio processing library\n",
    "import librosa\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "\n",
    "# for plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "# for accuracy and confusion matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# for data normalization\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER CONFIGURATION\n",
    "# Please alter the paths here to where the data are stored on your local filesystem\n",
    "binarylabelcsv  = os.path.expanduser(\"~/shared_storage/ECS7013P/bird_audio_detection/warblrb10k_public_metadata_2018.csv\")\n",
    "audiofilefolder = os.path.expanduser(\"~/shared_storage/ECS7013P/warblrb10k_public_wav\")\n",
    "\n",
    "# we experiment with 100 files here. In practice, it depends on your actual training, validation, and test data\n",
    "#maxfilestoload  = 1000      # limit, because loading the whole dataset is very slow\n",
    "maxfilestoload  = 100      # limit, because loading the whole dataset is very slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('759808e5-f824-401e-9058', 1.0)\n",
      "('1d94fc4a-1c63-4da0-9cac', 1.0)\n",
      "('bb0099ce-3073-4613-8557', 1.0)\n",
      "('c4c67e81-9aa8-4af4-8eb7', 1.0)\n",
      "('ab322d4b-da69-4b06-a065', 0.0)\n",
      "('519cfbe6-f804-4add-baa3', 0.0)\n",
      "('6332d960-6f57-4ecc-8d1a', 1.0)\n",
      "('db89b696-5ca0-4ca8-982a', 1.0)\n",
      "('a02ac7bc-5a29-40a1-89e1', 1.0)\n",
      "('6ce66c37-3a83-43b1-b0dd', 1.0)\n",
      "('126160c6-cd85-41f7-a5e7', 1.0)\n"
     ]
    }
   ],
   "source": [
    "# here we load the metadata labels\n",
    "binarylabels = {}\n",
    "with open(binarylabelcsv, 'r') as infp:\n",
    "        rdr = csv.DictReader(infp)\n",
    "        for row in rdr:\n",
    "                binarylabels[row['itemid']] = float(row['hasbird'])\n",
    "                if len(binarylabels)==maxfilestoload:\n",
    "                        break  # note, here we are restricting the maximum number of rows.\n",
    "\n",
    "fkeys = sorted(binarylabels.keys())\n",
    "# inspect:\n",
    "for i, kv in enumerate(binarylabels.items()):\n",
    "    print(kv)\n",
    "    if i==10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759808e5-f824-401e-9058\n",
      "1d94fc4a-1c63-4da0-9cac\n",
      "bb0099ce-3073-4613-8557\n",
      "c4c67e81-9aa8-4af4-8eb7\n",
      "ab322d4b-da69-4b06-a065\n",
      "519cfbe6-f804-4add-baa3\n",
      "6332d960-6f57-4ecc-8d1a\n",
      "db89b696-5ca0-4ca8-982a\n",
      "a02ac7bc-5a29-40a1-89e1\n",
      "6ce66c37-3a83-43b1-b0dd\n",
      "126160c6-cd85-41f7-a5e7\n",
      "19d149c7-98a8-48d2-921d\n",
      "4dd5046d-c962-4f02-a820\n",
      "479b90e3-85bf-403c-8298\n",
      "3661273c-19b9-4ea0-abc5\n",
      "5e8976e1-c7bf-45b7-b22b\n",
      "947e8e78-3f1d-4493-936f\n",
      "b7a49bf2-f898-41ec-be40\n",
      "d09bf6fc-6275-47b2-9a3e\n",
      "960784f4-34aa-4235-9d9c\n",
      "4c6d2568-17f6-4ca7-b347\n",
      "1e1ade85-72d2-4c85-b428\n",
      "efe349dd-319a-42bf-ae04\n",
      "e30d7c93-f1bc-4ca5-af31\n",
      "13562d9b-aa0b-42ca-9198\n",
      "f08f8ca2-59dd-4065-9abb\n",
      "b2952a5b-6e87-4b3d-b7a8\n",
      "98fe674f-985a-4434-aa82\n",
      "56239bc2-5af8-4586-b2c7\n",
      "bfee5f94-ed1d-48da-9681\n",
      "0a0b783d-f9a3-4652-a01d\n",
      "031f0a9b-446c-496f-8997\n",
      "1e860c93-dd38-4711-88de\n",
      "026eceb5-3e21-4fdc-b6d3\n",
      "9fe0ad8e-14bf-45f5-9429\n",
      "7c503dce-d6ad-4394-97b1\n",
      "345341a8-7d81-4ccb-ba4a\n",
      "c56549cc-af7b-4269-8fc5\n",
      "c95f2ba3-b863-439b-993a\n",
      "3718760f-e8c5-40c8-87b8\n",
      "42354fbc-fa9b-430d-b374\n",
      "d509daa6-afad-4d98-baee\n",
      "cfcb0d51-e8e9-4882-aa29\n",
      "2bc65db1-0fb0-4289-b8c1\n",
      "4aed9671-dc8a-477d-b12b\n",
      "666998e4-20c1-4765-bb39\n",
      "40a84a07-2d3b-443a-9643\n",
      "f78e11ef-ecdd-4941-ba67\n",
      "759ed722-0f94-493e-b406\n",
      "96dafde7-d6c6-4ebe-8bf2\n",
      "41e87fc5-c247-4b02-ae87\n",
      "afb64a2f-61fa-4325-8975\n",
      "331c7315-7300-4147-90b3\n",
      "c2fb90df-e81a-4f2d-95c2\n",
      "fc3c340e-79a7-42a1-bfdc\n",
      "37b45b7e-8014-4533-87b7\n",
      "1ab9d3e5-ff89-4ea7-a455\n",
      "f5cccdc0-a015-4593-aa4b\n",
      "7c1d1621-8903-47d0-b535\n",
      "952f1cba-e7a4-46fc-bfb2\n",
      "ce96ac2d-889c-409e-aeae\n",
      "382ce68b-1321-4ad6-8711\n",
      "be844b62-1698-4fc8-a887\n",
      "73a68b17-94ec-4e69-9e4b\n",
      "9a623967-3edc-4120-a558\n",
      "70cd7cf8-0b60-4d35-8db2\n",
      "0d8fae0c-e565-4177-adbb\n",
      "b69dc1e7-a2b4-4e26-b265\n",
      "1a01ceda-65d3-4c7a-bdf7\n",
      "ac0c4619-e242-490b-9192\n",
      "66b780d9-c038-463f-ac30\n",
      "86f13bcd-76b3-4bfe-8428\n",
      "0608b14d-544f-479e-81aa\n",
      "7fa03435-ec2f-4088-bcb4\n",
      "c1a458a6-c250-4660-91f9\n",
      "51c93921-470a-4d84-84ff\n",
      "af72708c-3aaa-4f23-87bf\n",
      "954f647b-6fde-44ba-bbe7\n",
      "dffd9912-62f5-4ed8-9955\n",
      "16f8ca73-5a06-4693-af9d\n",
      "20eaf521-e88e-4e8f-947b\n",
      "4eac3cb9-a047-4e83-9ea9\n",
      "c4e9f72e-f01a-456c-98a7\n",
      "bc1ea007-5a9c-451a-acd4\n",
      "910bf18b-8a20-4d67-9adb\n",
      "8371a72e-2b64-4e64-9227\n",
      "5b37f0f4-f525-48d1-9c98\n",
      "3070eeec-386f-42e1-b4bc\n",
      "ffe84fee-d4e6-4483-9113\n",
      "6d9d75c8-8035-46d6-8cd7\n",
      "47240129-5048-4b13-ad12\n",
      "b30b6751-9b18-4389-9589\n",
      "b6855df9-f4e4-4b32-8d6b\n",
      "63fac5d1-dd52-474f-9955\n",
      "fa568b98-bed3-4c9a-912b\n",
      "8530cc0a-b6d4-4642-96a9\n",
      "f0a13d56-b9b9-4e92-9318\n",
      "fca2231e-a8a4-4905-986f\n",
      "b48298ec-006c-4006-8f13\n",
      "47915a93-5d41-4c90-b429\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- Load an example audio file, converting the audio data to mel spectrogram\n",
    "- window length 50 ms, hop_len 25 ms\n",
    "'''\n",
    "def extract_melspectrogram(filename, win_len=0.05, hop_len=0.025, n_mels=64):\n",
    "    audio, sr = librosa.load(\"%s/%s.wav\" % (audiofilefolder, filename), sr=22050)\n",
    "    win_len = int(win_len*sr)\n",
    "    hop_len = int(hop_len*sr)\n",
    "    spec = librosa.feature.melspectrogram(audio, sr, n_mels=n_mels, n_fft=2048, win_length=win_len, hop_length=hop_len)\n",
    "    # return data format (time_len, n_mels)\n",
    "    return spec.transpose((1,0))\n",
    "'''\n",
    " - Load the data, \n",
    " - Extract mel spectrograms\n",
    " - Annotation: one element corresponding to one audio file\n",
    "'''\n",
    "data = np.zeros((maxfilestoload, 400, 64)) # for storing mel spectrograms\n",
    "label = np.zeros(maxfilestoload) # for storing the annotion\n",
    "for i, kv in enumerate(binarylabels.items()):\n",
    "    print(kv[0])\n",
    "    # the number of the melspectrograms' time frames varies a bit (due to some small differences in audio length)\n",
    "    # for simplicity, let's take a maximum of 400 time frames.\n",
    "    melspec = extract_melspectrogram(kv[0])\n",
    "    if(len(melspec) < 400):\n",
    "        melspec = np.pad(melspec, ((400-len(melspec),0),(0,0)))\n",
    "    data[i] = melspec[:400]\n",
    "    label[i] = kv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 400, 64)\n",
      "(10, 400, 64)\n",
      "(10, 400, 64)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- Split the data into \n",
    "    training (80%)\n",
    "    validation (10%)\n",
    "    test (10%)\n",
    "'''\n",
    "#print(label)\n",
    "#print(data.shape)\n",
    "#print(data[0])\n",
    "\n",
    "# training data\n",
    "train_data = data[:int(0.8*maxfilestoload)]\n",
    "train_label = label[:int(0.8*maxfilestoload)]\n",
    "print(train_data.shape)\n",
    "\n",
    "# validation data\n",
    "valid_data = data[int(0.8*maxfilestoload):int(0.9*maxfilestoload)]\n",
    "valid_label = label[int(0.8*maxfilestoload):int(0.9*maxfilestoload)]\n",
    "print(valid_data.shape)\n",
    "\n",
    "# test data\n",
    "test_data = data[int(0.9*maxfilestoload):]\n",
    "test_label = label[int(0.9*maxfilestoload):]\n",
    "print(test_data.shape)\n",
    "\n",
    "#del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.20791494e-01 9.64391566e-01 2.89431562e+00 3.78157927e+00\n",
      " 2.76027139e+00 1.78452657e+00 1.79662422e+00 1.43626160e+00\n",
      " 1.53025706e+00 1.43725899e+00 1.34187642e+00 9.01580792e-01\n",
      " 7.94863424e-01 9.08886755e-01 9.38719742e-01 9.98877398e-01\n",
      " 1.16789356e+00 1.15067610e+00 1.01053602e+00 7.92294295e-01\n",
      " 6.63644233e-01 5.78312027e-01 5.68667713e-01 4.96086765e-01\n",
      " 5.65720270e-01 5.38950945e-01 4.06807184e-01 3.62360494e-01\n",
      " 3.00438021e-01 3.19008672e-01 2.85847548e-01 3.35627510e-01\n",
      " 3.63672546e-01 5.53592367e-01 3.74909727e-01 2.67980823e-01\n",
      " 2.62757641e-01 2.55434710e-01 2.67096008e-01 1.97006626e-01\n",
      " 1.85187636e-01 1.32342670e-01 1.42885041e-01 1.19854611e-01\n",
      " 1.72176351e-01 1.62574243e-01 2.18439848e-01 1.76943503e-01\n",
      " 1.59127307e-01 6.16644894e-02 7.83198373e-02 6.16663548e-02\n",
      " 5.08809065e-02 6.14633521e-02 5.89586188e-02 6.33452124e-02\n",
      " 4.55618710e-02 4.00422790e-02 3.46592746e-02 2.16795920e-02\n",
      " 1.03177601e-02 7.68573427e-03 6.16053785e-03 1.94739536e-03]\n"
     ]
    }
   ],
   "source": [
    "# data normalisation\n",
    "scaler = StandardScaler()\n",
    "# compute normalisation parameters based on the training data \n",
    "# QUESTION: why do we reshape the data to (-1,64)?\n",
    "scaler.fit(train_data.reshape((-1,64)))\n",
    "print(scaler.mean_)\n",
    "\n",
    "# normalise the training data with the computed parameters\n",
    "train_data = scaler.transform(train_data.reshape((-1,64)))\n",
    "train_data = train_data.reshape((-1, 400, 64)) # reverse back to the original shape\n",
    "#print(train_data[0])\n",
    "\n",
    "# normalise the validation data with the computed parameters\n",
    "valid_data = scaler.transform(valid_data.reshape((-1,64)))\n",
    "valid_data = valid_data.reshape((-1, 400, 64)) # reverse back to the original shape\n",
    "#print(valid_data[0])\n",
    "\n",
    "# normalise the test data with the computed parameters\n",
    "test_data = scaler.transform(test_data.reshape((-1,64)))\n",
    "test_data = test_data.reshape((-1, 400, 64)) # reverse back to the original shape\n",
    "#print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \n",
    "    Ref: He, Kaiming, et al. \"Delving deep into rectifiers: Surpassing \n",
    "    human-level performance on imagenet classification.\" Proceedings of the \n",
    "    IEEE international conference on computer vision. 2015.\n",
    "    \"\"\"\n",
    "    \n",
    "    if layer.weight.ndimension() == 4:\n",
    "        (n_out, n_in, height, width) = layer.weight.size()\n",
    "        n = n_in * height * width\n",
    "        \n",
    "    elif layer.weight.ndimension() == 2:\n",
    "        (n_out, n) = layer.weight.size()\n",
    "\n",
    "    std = math.sqrt(2. / n)\n",
    "    scale = std * math.sqrt(3.)\n",
    "    layer.weight.data.uniform_(-scale, scale)\n",
    "\n",
    "    if layer.bias is not None:\n",
    "        layer.bias.data.fill_(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    \n",
    "    bn.weight.data.fill_(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnModel(nn.Module):\n",
    "    \"\"\"The CNN model\"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CnnModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64,\n",
    "                               kernel_size=(5, 5), bias=False)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128,\n",
    "                               kernel_size=(5, 5), bias=False)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=128,\n",
    "                               kernel_size=(3, 3), bias=False)\n",
    "\n",
    "        self.fc1 = nn.Linear(128*2*1, 128, bias=True)\n",
    "        self.fc2 = nn.Linear(128, 1, bias=True)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_layer(self.conv3)\n",
    "        init_layer(self.fc1)\n",
    "\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "        init_bn(self.bn3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        (_, time_len, mel_bins) = x.shape\n",
    "\n",
    "        x = x.view(-1, 1, time_len, mel_bins)\n",
    "        #print('Input')\n",
    "        #print(x.size())\n",
    "\n",
    "        x = nnF.relu(self.bn1(self.conv1(x)))\n",
    "        #print('Conv1')\n",
    "        #print(x.size())\n",
    "        x = nnF.max_pool2d(x,kernel_size=(8,4),padding=(4,0))\n",
    "        #print('Pool1')\n",
    "        #print(x.size())\n",
    "        \n",
    "        x = nnF.relu(self.bn2(self.conv2(x)))\n",
    "        #print('Conv2')\n",
    "        #print(x.size())\n",
    "        x = nnF.max_pool2d(x,kernel_size=(8,4),padding=(2,1))\n",
    "        #print('Pool2')\n",
    "        #print(x.size())\n",
    "        \n",
    "        x = nnF.relu(self.bn3(self.conv3(x)))\n",
    "        #print('Conv3')\n",
    "        #print(x.size())\n",
    "        x = nnF.max_pool2d(x,kernel_size=(2,1))\n",
    "        #print('Pool3')\n",
    "        #print(x.size())\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = nnF.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward_and_convert(self, x):\n",
    "        \"Handles the torch<--->numpy tensor conversion, for convenience\"\n",
    "        x_torch = torch.FloatTensor(x)\n",
    "        y_torch = self.forward(x_torch)\n",
    "        return y_torch.detach().numpy()\n",
    "        \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CnnModel(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create a model instance\n",
    "net = CnnModel()\n",
    "print(net)\n",
    "\n",
    "# Binary-cross entropy loss, closely related to logistic regression loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Adam Optimizer, learning rate 0.001\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minibatch size (remember stochastic gradient descent?)\n",
    "batch_size = 4\n",
    "\n",
    "# some helpful functions\n",
    "\n",
    "'''\n",
    "Evaluate a network \"model\" on the data \"data\" \n",
    "Predicted class labels will be returned\n",
    "'''\n",
    "def evaluate(model, data):\n",
    "    pred = np.zeros(len(data)) # for storing predicted class labels, one for each data sample\n",
    "    num_batch = len(data)//batch_size # number of batches in one data epoch\n",
    "    # evaluate batch by batch and store the output to \"pred\"\n",
    "    for i in range(num_batch):\n",
    "        temp = model.forward_and_convert(data[i*num_batch : (i+1)*num_batch])\n",
    "        # QUESTION: what does squeeze() function do?\n",
    "        pred[i*num_batch : (i+1)*num_batch] = temp.squeeze()\n",
    "    # some trailing data samples\n",
    "    if(num_batch*batch_size < len(data)):\n",
    "        temp = model.forward_and_convert(data[num_batch*batch_size :])\n",
    "        pred[num_batch*batch_size :] = temp.squeeze()\n",
    "    # each element in \"pred\" is the output after sigmoid function and has value in [0, 1].\n",
    "    # to obtain the discrete label (0 or 1 in this case), we threshold the value by 0.5.\n",
    "    pred[pred >= 0.5] = 1.\n",
    "    pred[pred < 0.5] = 0.\n",
    "    return pred\n",
    "\n",
    "'''\n",
    "Randomly shuffle the data. It will be used to shuffle the training data after every training epoch\n",
    "'''\n",
    "def shuffle_data(data, label):\n",
    "    # permute the data indices\n",
    "    rand_ind = np.random.permutation(len(data))\n",
    "    # re-order the data with the pumuted indices\n",
    "    return data[rand_ind], label[rand_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] loss: 0.21287803\n",
      "Validation accuracy: 0.6\n",
      "Saving best model\n",
      "[1] loss: 0.38553396\n",
      "Validation accuracy: 0.6\n",
      "[2] loss: 0.41485715\n",
      "Validation accuracy: 0.6\n",
      "[3] loss: 0.20125622\n",
      "Validation accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "'''The training loop'''\n",
    "\n",
    "num_epochs = 100 # the number of training epoch (i.e. when you've gone through all samples of the training data, that's one epoch)\n",
    "evaluate_every_epoch = 1 # how often you want to evaluate the network during training?\n",
    "best_valid_acc = 0.0 # for keeping track of the best accuracy on the validation data\n",
    "saved_model = './best_model' # path for saving the best model during training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # shuffle training data\n",
    "    train_data, train_label = shuffle_data(train_data, train_label)\n",
    "    \n",
    "    # the number of minibatch in one epoch\n",
    "    num_batch = len(train_data) // batch_size\n",
    "    for i in range(num_batch):\n",
    "        # sample one minibatch\n",
    "        batch_data = train_data[i*batch_size : (i+1)*batch_size]\n",
    "        label_data = train_label[i*batch_size : (i+1)*batch_size]\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(torch.FloatTensor(batch_data))\n",
    "        loss = criterion(outputs.squeeze(), torch.FloatTensor(label_data))\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    running_loss = loss.item()\n",
    "    # print training loss\n",
    "    print('[%d] loss: %.8f' %(epoch, running_loss))\n",
    "    \n",
    "    # evaluate the network on the validation data\n",
    "    if((epoch+1) % evaluate_every_epoch == 0):\n",
    "        valid_pred = evaluate(net, valid_data)\n",
    "        valid_acc = accuracy_score(valid_pred, valid_label)\n",
    "        print('Validation accuracy: %g' % valid_acc)\n",
    "        \n",
    "        # if the best validation performance so far, save the network to file \n",
    "        if(best_valid_acc < valid_acc):\n",
    "            best_valid_acc = valid_acc\n",
    "            print('Saving best model')\n",
    "            torch.save(net.state_dict(), saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''When you are here, we have the best model saved in file.'''\n",
    "'''Then, load the saved model, and evaluate it on the test data'''\n",
    "net = CnnModel()\n",
    "net.load_state_dict(torch.load(saved_model)) # load the saved model\n",
    "\n",
    "# evaluate on the test data\n",
    "test_pred = evaluate(net, test_data) \n",
    "print(test_pred)\n",
    "\n",
    "# test accuracy\n",
    "test_acc = accuracy_score(test_pred, test_label)\n",
    "print('Test accuracy: %g' % test_acc)\n",
    "\n",
    "# confusion matrix\n",
    "confusion_matrix(test_label, test_pred)\n",
    "print('Confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
