{"cells":[{"cell_type":"markdown","metadata":{"id":"cLHNA01ChQM3"},"source":["\n","### **Generating Abstract Cartoon Images with Generative Adversarial Networks and Neural Style Transfer**\n","\n","Jiahui Shao, Student ID: 210934641\n","\n"]},{"cell_type":"markdown","metadata":{"id":"a9KodGsgl_q5"},"source":["## Logistics Code:"]},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","executionInfo":{"elapsed":8694,"status":"ok","timestamp":1650463819248,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"},"user_tz":-60},"id":"ve7B5Sd52GVa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"031b93df-6cc5-455f-e673-a6cc11e5e91a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  \n"]}],"source":["#@title Imports\n","\n","import tensorflow as tf\n","import keras\n","import numpy as np\n","from tqdm.autonotebook import tqdm\n","from IPython import display\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import os\n","import imageio as iio\n","import random \n","import tensorflow_hub as hub\n","# from tensorflow.keras import applications\n","# from tensorflow.keras.utils import plot_model\n","# from keras import Model\n","# from tensorflow.keras.optimizers import SGD\n","%config InlineBackend.figure_format = 'retina'\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","id":"Ox2aEKGb-r3Q","executionInfo":{"status":"ok","timestamp":1650463819249,"user_tz":-60,"elapsed":14,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":[" # @title Load GAN dataset\n","\n","# # Load cartoon headshot datasets from Google Drive into 'train_images' and 'test_images' variables\n","# training_path = '/content/gdrive/My Drive/ECS7022P/datasets/training_set/'\n","# test_path = '/content/gdrive/My Drive/ECS7022P/datasets/test_set/'\n","\n","# data_training = []\n","# data_test = []\n","\n","# for filename in os.listdir(training_path):\n","#   image = Image.open(training_path + filename)\n","#   data_training.append(np.asarray(image))\n","\n","# for filename in os.listdir(test_path):\n","#   image = Image.open(test_path + filename)\n","#   data_test.append(np.asarray(image))\n","\n","# train_images = np.array(data_training)\n","# test_images = np.array(data_test)\n","# random.shuffle(train_images)  # shuffle the training set\n","# random.shuffle(test_images)  # shuffle the test set \n","\n","# print('train_images.shape: {}'.format(train_images.shape))  # 80% datasets for training\n","# print('test_images.shape: {}'.format(test_images.shape))  # 20% datasets for test"]},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","id":"vEJngsesWp_1","executionInfo":{"status":"ok","timestamp":1650463819249,"user_tz":-60,"elapsed":10,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title Displaying the training images of the GAN phase \n","\n","# Helper function for displaying images\n","def show_images(images):\n","    if len(images.shape) > 3 and images.shape[3] == 1:\n","        if tf.is_tensor(images):\n","            images = images.numpy()\n","        images = np.squeeze(images, axis=3)\n","\n","    num_images = len(images)\n","    fig, cells = plt.subplots(ncols=num_images, nrows=1, figsize=(2 * num_images, 2))\n","    for cell_num in range(num_images):\n","        cells[cell_num].matshow(images[cell_num])\n","        cells[cell_num].axis('off')\n","    plt.show()\n","\n","# # Show some of the training images\n","# n_images =  16#@param{type: \"integer\"}\n","# images_display = train_images\n","# if n_images > 0:\n","#     images_display = images_display[:n_images]\n","\n","# # Display!\n","# show_images(images_display)"]},{"cell_type":"code","execution_count":4,"metadata":{"cellView":"form","id":"ED8r7h_OBJ1G","executionInfo":{"status":"ok","timestamp":1650463819250,"user_tz":-60,"elapsed":9,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title Data pre-processing\n","\n","# # default: 512\n","# BATCH_SIZE = 256 # @param {type:\"slider\", min:128, max:1024, step:128}\n","\n","# N_CHANNELS = (train_images.shape[-1] if len(train_images.shape)>3 else 1)\n","# TRAIN_BUF = len(train_images)\n","# IMG_SIZE = len(train_images[0])\n","# DIMS = (IMG_SIZE, IMG_SIZE, N_CHANNELS)\n","# N_TRAIN_BATCHES = int(TRAIN_BUF/BATCH_SIZE)\n","\n","# N_CHANNELS_TEST = (test_images.shape[-1] if len(test_images.shape)>3 else 1)\n","# TEST_BUF = len(test_images)\n","# IMG_SIZE_TEST = len(test_images[0])\n","# N_TEST_BATCHES = int(TEST_BUF/BATCH_SIZE)\n","\n","# print(\"Batch size: {} \\nTraining set size: {}\\\n","#        \\nTest set size: {}\\nImage Dimensions: {}\\\n","#        \\n# Train batches: {}\\n# Test batches: {}\".format(\n","#             BATCH_SIZE, TRAIN_BUF, TEST_BUF, DIMS, N_TRAIN_BATCHES, N_TEST_BATCHES\n","#         )\n","# )\n","\n","BATCH_SIZE = 256\n","\n","N_CHANNELS = 3\n","TRAIN_BUF = 4000\n","IMG_SIZE = 64\n","DIMS = (64,64,3)\n","N_TRAIN_BATCHES = 15\n","\n","N_CHANNELS_TEST = 3\n","TEST_BUF = 1000\n","IMG_SIZE_TEST = 64\n","N_TEST_BATCHES = 3"]},{"cell_type":"code","execution_count":5,"metadata":{"cellView":"form","id":"HVt0Rx8uKXWF","executionInfo":{"status":"ok","timestamp":1650463819250,"user_tz":-60,"elapsed":9,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title Normalise data\n","\n","# # Normalise the data between 0 and 1. First apply the .astype(\"float32\") function to the training dataset. Next, given that the colour layers go between 0 and 255, divide by 255.0 the 'train_images' and 'test_images' variable.\n","# train_images = train_images.reshape(train_images.shape[0], IMG_SIZE, IMG_SIZE, N_CHANNELS).astype(\"float32\")\n","# train_images = train_images/255.0  # (train_images - 127.5) / 127.5\n","# test_images = test_images.reshape(test_images.shape[0], IMG_SIZE_TEST, IMG_SIZE_TEST, N_CHANNELS_TEST).astype(\"float32\")\n","# test_images = test_images/255.0  # (train_images - 127.5) / 127.5"]},{"cell_type":"code","execution_count":6,"metadata":{"cellView":"form","id":"zuSRAsmmBLjV","executionInfo":{"status":"ok","timestamp":1650463819250,"user_tz":-60,"elapsed":8,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title Batch datasets\n","\n","# # create batch size for training \n","# train_dataset = (\n","#     tf.data.Dataset.from_tensor_slices(train_images)\n","#     .shuffle(TRAIN_BUF)\n","#     .batch(BATCH_SIZE)\n","# )\n","\n","# test_dataset = (\n","#     tf.data.Dataset.from_tensor_slices(test_images)\n","#     .shuffle(TEST_BUF)\n","#     .batch(BATCH_SIZE)\n","# )"]},{"cell_type":"code","execution_count":7,"metadata":{"cellView":"form","id":"bRUbg3-_c2Hc","executionInfo":{"status":"ok","timestamp":1650463820394,"user_tz":-60,"elapsed":1151,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title Set up generator network structure\n","\n","# default: \"relu\"\n","activation_l0 = \"relu\" #@param{type: \"string\"}\n","# default: \"relu\"\n","activation_l2 = \"relu\" #@param{type: \"string\"}\n","# default: \"relu\"\n","activation_l3 = \"relu\" #@param{type: \"string\"}\n","# default: \"sigmoid\"\n","activation_l4 = \"sigmoid\" #@param{type: \"string\"}\n","\n","n_stride = 2  # factor to scale image up by in each convolution layer\n","n_layers_stride = 2  # number of layers scaling the image up\n","n_smallest_dim = IMG_SIZE//(n_stride*n_layers_stride)\n","seed_size = IMG_SIZE * (2 ** (n_layers_stride-1)) * N_CHANNELS\n","\n","# Generator structure, 5 layers: Dense, Reshape, 3xConvolutionTranspose\n","generator = [\n","    tf.keras.layers.Dense(units=n_smallest_dim * n_smallest_dim * seed_size, activation=activation_l0),\n","    tf.keras.layers.Reshape(target_shape=(n_smallest_dim, n_smallest_dim, seed_size)),\n","    tf.keras.layers.Conv2DTranspose(\n","        filters=seed_size, kernel_size=3, strides=(n_stride, n_stride), padding=\"SAME\", activation=activation_l2\n","    ),\n","    tf.keras.layers.Conv2DTranspose(\n","        filters=seed_size/2, kernel_size=3, strides=(n_stride, n_stride), padding=\"SAME\", activation=activation_l3\n","    ),\n","    tf.keras.layers.Conv2DTranspose(\n","        filters=N_CHANNELS, kernel_size=3, strides=(1, 1), padding=\"SAME\", activation=activation_l4\n","    ),\n","]\n","\n","#-- Optimiser\n","# default: 0.001\n","opt_learning_rate = 0.0001  #@param{type:\"raw\"}\n","# default: 0.5\n","opt_beta = 0.4 #@param{type:\"raw\"}\n","gen_optimizer = tf.keras.optimizers.Adam(opt_learning_rate, beta_1=opt_beta)\n","\n","# Build the network\n","gen = tf.keras.Sequential(generator)\n","# gen.build([train_images.shape[0], 1, 1, seed_size])  # specifies input shape\n","gen.build([4000, 1, 1, seed_size]) \n","# Print network summary\n","# gen.summary()"]},{"cell_type":"code","execution_count":8,"metadata":{"cellView":"form","id":"m6RYXXrBdrd5","executionInfo":{"status":"ok","timestamp":1650463820813,"user_tz":-60,"elapsed":421,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title Set up discriminator network structure\n","\n","# default: \"relu\"\n","activation_l1 = \"relu\" #@param{type: \"string\"}\n","# default: \"relu\"\n","activation_l2 = \"relu\" #@param{type: \"string\"}\n","\n","# Discriminator structure: 5 layers, Input + Convolutionx2 + Flatten + Dense\n","discriminator = [\n","    tf.keras.layers.InputLayer(input_shape=DIMS),\n","    tf.keras.layers.Conv2D(\n","        filters=seed_size/2, kernel_size=3, strides=(n_stride, n_stride), activation=activation_l1\n","    ),\n","    tf.keras.layers.Conv2D(\n","        filters=seed_size, kernel_size=3, strides=(n_stride, n_stride), activation=activation_l2\n","    ),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(units=1, activation=None),\n","]\n","\n","#-- Optimiser\n","# default: 0.005\n","opt_learning_rate = 0.0001  #@param{type:\"raw\"}\n","disc_optimizer = tf.keras.optimizers.RMSprop(opt_learning_rate)\n","\n","# Build the network\n","disc = tf.keras.Sequential(discriminator)\n","disc.compile(loss='binary_crossentropy', optimizer= disc_optimizer , metrics = ['accuracy'])\n","disc.build(DIMS)  # specifies input shape\n","\n","# Print network summary\n","# disc.summary()"]},{"cell_type":"code","execution_count":9,"metadata":{"cellView":"form","id":"FWl9hrtnd6bK","executionInfo":{"status":"ok","timestamp":1650463820813,"user_tz":-60,"elapsed":9,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title Set up the GAN as a Keras model object.\n","\n","class GAN(tf.keras.Model):\n","    \"\"\" \n","    A basic GAN class. Extends tf.keras.Model\n","    \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super(GAN, self).__init__()\n","        self.__dict__.update(kwargs)\n","\n","        self.gen = self.gen\n","        self.disc = self.disc\n","\n","    def call(self, x):\n","        return self.gen(x)\n","\n","    def generate(self, z):\n","        \"\"\"\n","        Run input vector z through the generator to create fake data.\n","        \"\"\"\n","        return self.gen(z)\n","\n","    def discriminate(self, x):\n","        \"\"\"\n","        Run data through the discriminator to label it as real or fake.\n","        \"\"\"\n","        return self.disc(x)\n","\n","    def compute_loss(self, x):\n","        \"\"\" \n","        Passes through the network and computes loss for given data.\n","        \"\"\"\n","        # Generate a random vector seed from a uniform distribution\n","        seed = tf.random.normal([x.shape[0], 1, 1, self.seed_size])\n","\n","        # Use the seed to generate a fake data set with the generator network.\n","        fakes = self.generate(seed)\n","\n","        # Use the discriminator network to obtain labels for both the generated data (x_gen) and the real data (x)\n","        logits_reals = self.discriminate(x)\n","        logits_fakes = self.discriminate(fakes)\n","\n","        # Discriminator loss, looking at correctly labeled data\n","        # Losses of the real data with correct label \"1\"\n","        disc_real_loss = gan_loss(logits=logits_reals, is_real=True)\n","        # Losses of the fake data with correct label \"0\"\n","        disc_fake_loss = gan_loss(logits=logits_fakes, is_real=False)\n","        # The discriminator loss is the sum of the 2 previous values\n","        disc_loss = disc_fake_loss + disc_real_loss\n","\n","        # Generator loss, looking at the fake data labeled as real (\"1\")\n","        gen_loss = gan_loss(logits=logits_fakes, is_real=True)\n","\n","        # Return losses\n","        return disc_loss, gen_loss\n","\n","    def compute_gradients(self, x):\n","        \"\"\" \n","        Passes through the network and computes gradients.\n","        \"\"\"\n","        ### Pass x through network and compute losses\n","        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","            disc_loss, gen_loss = self.compute_loss(x)\n","\n","        # Compute gradients\n","        gen_gradients = gen_tape.gradient(gen_loss, self.gen.trainable_variables)\n","        disc_gradients = disc_tape.gradient(disc_loss, self.disc.trainable_variables)\n","\n","        return gen_gradients, disc_gradients\n","\n","    def apply_gradients(self, gen_gradients, disc_gradients):\n","        \"\"\"\n","        Apply given gradients to both networks.\n","        \"\"\"\n","        self.gen_optimizer.apply_gradients(zip(gen_gradients, self.gen.trainable_variables))\n","        self.disc_optimizer.apply_gradients(zip(disc_gradients, self.disc.trainable_variables))\n","\n","    @tf.function\n","    def train(self, train_x):\n","        \"\"\"\n","        Train the GAN! \n","        \"\"\"\n","        gen_gradients, disc_gradients = self.compute_gradients(train_x)\n","        self.apply_gradients(gen_gradients, disc_gradients)\n","        \n","        \n","def gan_loss(logits, is_real=True):\n","    \"\"\"\n","    Computes cross entropy between logits and labels\n","    \"\"\"\n","    if is_real:\n","        labels = tf.ones_like(logits)\n","    else:\n","        labels = tf.zeros_like(logits)\n","\n","    # Returns loss calculation\n","    return tf.nn.sigmoid_cross_entropy_with_logits(labels, logits)\n","\n","\n","# Set up the model\n","\n","model = GAN(\n","    gen = gen,\n","    disc = disc,\n","    gen_optimizer = gen_optimizer,\n","    disc_optimizer = disc_optimizer,\n","    seed_size = seed_size\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"cellView":"form","id":"74uTdY6OEvwb","executionInfo":{"status":"ok","timestamp":1650463820814,"user_tz":-60,"elapsed":7,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title VGG model choice (style transfer)\n","# network_choice = \"vgg19\" #@param['vgg19', 'vgg16']\n","\n","# switcher1 = {\n","#     \"vgg19\": applications.vgg19,\n","#     \"vgg16\": applications.vgg16,\n","# }\n","# switcher2 = {\n","#     \"vgg19\": applications.vgg19.VGG19(weights=\"imagenet\", include_top=False),\n","#     \"vgg16\": applications.vgg16.VGG16(weights=\"imagenet\", include_top=False),\n","# }\n","# network = switcher1[network_choice]\n","\n","# def build_model():\n","#     model = switcher2[network_choice]\n","#     model.summary()\n","#     return model"]},{"cell_type":"code","execution_count":11,"metadata":{"cellView":"form","id":"RJYvTceiEv18","executionInfo":{"status":"ok","timestamp":1650463820814,"user_tz":-60,"elapsed":6,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title Display images function (style transfer)\n","\n","def display_images(content_image, style_image, combination_image, num):\n","    \"\"\"\n","    Displays content, style and combination images, labelled. Any could be missing if set to None\n","    \"\"\"\n","    _, cells = plt.subplots(1, 3, figsize=(25,10))\n","    if content_image is not None:\n","        cells[0].imshow(content_image)\n","        cells[0].set_title(\"Content\", fontsize=15)\n","    if style_image is not None:\n","        cells[1].imshow(style_image)\n","        cells[1].set_title(\"Style\", fontsize=15)\n","    if combination_image is not None:\n","        cells[2].imshow(combination_image)\n","        cells[2].set_title(\"Artefact {}\".format(num), fontsize=15)\n","    for cell in cells:\n","        cell.axis('off')\n","    plt.show()"]},{"cell_type":"code","execution_count":12,"metadata":{"cellView":"form","id":"oEvZNd21Ev9u","executionInfo":{"status":"ok","timestamp":1650463820814,"user_tz":-60,"elapsed":5,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title Image pre-processing (style transfer)\n","# content_image = keras.preprocessing.image.load_img('/content/gdrive/My Drive/ECS7022P/media/images/content.png')\n","# style_image = keras.preprocessing.image.load_img('/content/gdrive/My Drive/ECS7022P/media/images/style2.png')\n","# # Turn images into Numpy arrays to extract full dimensions\n","# content_image_np = keras.preprocessing.image.img_to_array(content_image)\n","# style_image_np = keras.preprocessing.image.img_to_array(style_image)\n","\n","# # Setting image dimensions variables\n","# height = content_image_np.shape[0]\n","# width = content_image_np.shape[1]\n","# channels = content_image_np.shape[2]\n","# # Set height\n","# img_height = 400  #@param{type: 'number'}\n","# # Scale width appropriately\n","# img_width = int(width * img_height / height) \n","# img_size = img_height * img_width\n","\n","# def preprocess_image(image_path):\n","#     \"\"\"\n","#     Open, resize and format pictures into appropriate tensors\n","#     \"\"\"\n","#     # Load image with given size into PIL format\n","#     img = keras.preprocessing.image.load_img(\n","#         image_path, target_size=(img_height,img_width)\n","#     )  \n","#     # Turn image into Numpy array\n","#     img = keras.preprocessing.image.img_to_array(img)\n","#     # The next step expects a batch of images, so add another dimension\n","#     img = np.expand_dims(img, axis=0)  \n","#     # Call the network preprocessing step. \n","#     # Converts to BGR and zero-centers data with regards to the Imagenet dataset, by subtracting the mean channel values in Imagenet\n","#     img = network.preprocess_input(img)  \n","#     # Transform to tensor\n","#     return tf.convert_to_tensor(img)  \n","\n","# def deprocess_image(tensor):\n","#     \"\"\"\n","#     Reverse the preprocessing step to turn the tensor into an RGB Numpy array which we can visualise\n","#     \"\"\"\n","#     # Transform the tensor into a Numpy array\n","#     img = tensor.numpy()[0]\n","\n","#     # Return BGR values to normal (non-zero-centered), adding back in the means of the Imagenet dataset\n","#     img[:, :, 0] += 103.939\n","#     img[:, :, 1] += 116.779\n","#     img[:, :, 2] += 123.68\n","\n","#     # Convert from BGR to RGB\n","#     img = img[:, :, ::-1]\n","\n","#     # Ensure values are in valid ranges\n","#     img = np.clip(img, 0, 255).astype(\"uint8\")\n","\n","#     return img"]},{"cell_type":"code","execution_count":13,"metadata":{"cellView":"form","id":"ommzPaKXSxz8","executionInfo":{"status":"ok","timestamp":1650463821226,"user_tz":-60,"elapsed":417,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title Build the VGG19 model (style transfer)\n","# model = build_model()\n","\n","# # Set up a model to extract features, given input, for each layer in the network\n","# outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n","# feature_extractor = Model(inputs=model.inputs, outputs=outputs_dict)\n","\n","# initial_learning_rate = 100.0 #@param\n","# decay_steps = 100 #@param\n","# decay_rate = 0.96 #@param\n","\n","# optimizer = SGD(tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=initial_learning_rate, decay_steps=decay_steps, decay_rate=decay_rate))\n","\n","# def gram_matrix(input_tensor):\n","#     \"\"\"\n","#     Calculate the Gram matrix for given input\n","#     \"\"\"\n","#     input_tensor = tf.transpose(input_tensor, (2, 0, 1))  # Transpose\n","#     features = tf.reshape(input_tensor, (tf.shape(input_tensor)[0], -1))  # Flatten layer\n","#     gram = tf.matmul(features, tf.transpose(features))\n","#     return gram\n","\n","# def style_loss(style, combination):\n","#     \"\"\"\n","#     The style loss is the mean square error between the Gram matrix of the style image features and the Gram matrix of the combination image features,\n","#     divided by 4 in original paper (see link at the end of the notebook)\n","#     \"\"\"\n","#     S = gram_matrix(style)\n","#     C = gram_matrix(combination)\n","#     return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (img_size ** 2))\n","\n","# def content_loss(content, combination):\n","#     \"\"\"\n","#     The content loss is the mean square error between the combination and the content image features\n","#     \"\"\"\n","#     return tf.reduce_sum(tf.square(combination - content))\n","\n","# # Set which layers of the network should be taken into consideration when calculating content and style loss\n","# style_layers = [\n","#     \"block1_conv1\",\n","#     \"block2_conv1\",\n","#     \"block3_conv1\",\n","#     \"block4_conv1\",\n","#     \"block5_conv1\",\n","# ]\n","# content_layers = [\"block5_conv2\"]\n","\n","# # Total loss is a weighted sum of content and style loss\n","# content_weight = 1e-8  #@param\n","# # style_weight = 1e-6\n","# style_weight = 5e-6  #@param\n","# content_weight /= len(content_layers)\n","# style_weight /= len(style_layers)\n","\n","# def loss_function(combination_image, content_image, style_image):\n","#     \"\"\"\n","#     Calculate the loss function given a content image, a style image and the combination result\n","#     \"\"\"\n","#     # Combine all the images in the same tensor\n","#     input_tensor = tf.concat(\n","#         [content_image, style_image, combination_image], axis=0\n","#     )\n","\n","#     # Get the features in all the layers for the three images\n","#     features = feature_extractor(input_tensor)\n","\n","#     # Initialise the loss\n","#     loss = tf.zeros(shape=())\n","\n","#     # Extract the content layers and calculate the content loss\n","#     for layer_name in content_layers:\n","#         layer_features = features[layer_name]\n","#         content_image_features = layer_features[0, :, :, :]  # Content image is at position 0\n","#         combination_image_features = layer_features[2, :, :, :]  # Combination image is at position 2\n","#         loss += content_weight * content_loss(content_image_features, combination_image_features)\n","\n","#     # Extract the style layers and calculate the style loss\n","#     for layer_name in style_layers:\n","#         layer_features = features[layer_name]\n","#         style_image_features = layer_features[1, :, :, :]  # Style image is at position 1\n","#         combination_image_features = layer_features[2, :, :, :]\n","#         loss += style_weight * style_loss(style_image_features, combination_image_features)\n","\n","#     return loss\n","\n","# def compute_loss_and_grads(content_image, style_image, combination_image):\n","#     \"\"\"\n","#     Brings together the calculation of loss and that of gradients\n","#     \"\"\"\n","#     with tf.GradientTape() as tape:\n","#         loss = loss_function(combination_image, content_image, style_image)\n","#         grads = tape.gradient(loss, combination_image)\n","#     return loss, grads\n","\n","# # Compile the model\n","# model.compile(optimizer, loss_function)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"cellView":"form","id":"IWfwl4MhSx6p","executionInfo":{"status":"ok","timestamp":1650463821227,"user_tz":-60,"elapsed":13,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title Saving function (style transfer)\n","\n","# from google.colab import drive\n","# drive.mount('/content/gdrive')\n","\n","# # Directory where the checkpoints will be saved\n","# path = '/content/gdrive/My Drive/ECS7022P/models/' #@param{type: 'string'}\n","\n","# def save(epoch, img_tensor, save_image=True, save_model=False):\n","#   # model_name = path + \"model_\" + str(epoch) + '.tf'\n","#   model_name = path + \"ST\" + '.tf'\n","#   # model_name = 'ST' + '.tf'\n","#   image_name = path + \"img_\" + str(epoch) + '.png'\n","\n","#   # Save image\n","#   if save_image:\n","#       img = deprocess_image(img_tensor)\n","#       keras.preprocessing.image.save_img(image_name, img)\n","\n","#   # Save model\n","#   if save_model:\n","#       # tf.saved_model.save(model, model_name)\n","#       tf.saved_model.save(model,model_name)"]},{"cell_type":"markdown","metadata":{"id":"A87PQZNRT7vY"},"source":["## Training Code:"]},{"cell_type":"code","execution_count":15,"metadata":{"cellView":"form","id":"-g0RQqbBex0q","executionInfo":{"status":"ok","timestamp":1650463821227,"user_tz":-60,"elapsed":12,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title GAN traning\n","\n","# # default: 50\n","# n_epochs =  800# @param{type: \"integer\"} \n","\n","# losses = pd.DataFrame(columns = ['disc_loss', 'gen_loss'])\n","\n","# for epoch in range(n_epochs):\n","\n","#     # Train the model\n","#     for batch, train_x in tqdm(zip(range(N_TRAIN_BATCHES), train_dataset), total=N_TRAIN_BATCHES):\n","#       model.train(train_x)\n","\n","#     # At this point we could also test the model, compute losses and display them during training (if we'd kept training and test images separate)\n","#     loss = []\n","#     # for batch, test_x in tqdm(zip(range(N_TEST_BATCHES), test_dataset), total=N_TEST_BATCHES):\n","#     loss.append(model.compute_loss(train_x))\n","#     a = np.mean(loss, axis=0)\n","#     a = a[:,:,0]\n","#     avg_1 = np.mean(a[0,:])\n","#     avg_2 = np.mean(a[1,:])\n","#     losses.loc[len(losses)] = [avg_2, avg_1]\n","#     # losses.loc[len(losses)] = np.mean(loss)\n","\n","#     # Display epoch and images generate at this point in training\n","#     display.clear_output()  # This line clears output between epochs\n","#     print(\n","#         \"Epoch: {} | disc_loss: {} | gen_loss: {}\".format(\n","#             epoch+1, losses.disc_loss.values[-1], losses.gen_loss.values[-1]\n","#         )\n","#     )\n","#     print(\"Epoch: {}\".format(epoch+1))\n","#     generated_images = model.gen(tf.random.normal(shape=(10, seed_size)))\n","\n","#     # save the generated images at the 20th, 100th, 250th, and 500th epoch\n","#     if int(epoch+1)==20 or int(epoch+1)==100 or int(epoch+1)==250 or int(epoch+1)==500 or int(epoch+1)==750: \n","#       for i in range(9):\n","#         plt.subplot(3,3,i+1)\n","#         plt.imshow(generated_images[i,:,:,:])\n","#         plt.axis('off')\n","#         plt.savefig('/content/gdrive/My Drive/ECS7022P/media/outputs/GAN_image/epoch:{}.png'.format(epoch+1))  # store the images \n","#       plt.show()\n","#       display.clear_output() \n","    \n","#     show_images(generated_images)"]},{"cell_type":"code","execution_count":16,"metadata":{"cellView":"form","id":"BkydgHJcRgFN","executionInfo":{"status":"ok","timestamp":1650463821227,"user_tz":-60,"elapsed":10,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title Display the loss curve during the GAN training process\n","# plt.plot(losses['disc_loss'], label='disc_loss')\n","# plt.plot(losses['gen_loss'], label='gen_loss')\n","# plt.title('the loss curve')\n","# plt.legend()\n","# plt.savefig('/content/gdrive/My Drive/ECS7022P/media/outputs/GAN_image/loss_cruve')  # store the images \n","# plt.show()"]},{"cell_type":"code","execution_count":17,"metadata":{"cellView":"form","id":"eONE9GSoK4zV","executionInfo":{"status":"ok","timestamp":1650463821228,"user_tz":-60,"elapsed":10,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title Save GAN training model to GDrive\n","\n","# from google.colab import drive\n","# drive.mount('/content/gdrive')\n","\n","# gen_save_name = 'gen' #@param{type: 'string'}\n","# gen_save_name += '.tf'  # Set extension separately\n","# disc_save_name = 'disc' #@param{type: 'string'}\n","# disc_save_name += '.tf' # Set extension separately\n","\n","# path = 'My Drive/ECS7022P/models/' #@param{type: 'string'}\n","# full_path_g = F\"/content/gdrive/{path}{gen_save_name}\" \n","# full_path_d = F\"/content/gdrive/{path}{disc_save_name}\" \n","\n","# gen.save(full_path_g, save_format='tf')\n","# disc.save(full_path_d, save_format='tf')"]},{"cell_type":"code","execution_count":18,"metadata":{"cellView":"form","id":"2VlElmTMEahw","executionInfo":{"status":"ok","timestamp":1650463821228,"user_tz":-60,"elapsed":9,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"outputs":[],"source":["#@title VGG19 training and save VGG19 training model to GDrive\n","\n","# content_image_tensor = preprocess_image('/content/gdrive/My Drive/ECS7022P/media/images/content.png')\n","# style_image_tensor = preprocess_image('/content/gdrive/My Drive/ECS7022P/media/images/style1.png')\n","# combination_image_tensor = tf.Variable(preprocess_image('/content/gdrive/My Drive/ECS7022P/media/images/content.png'))\n","\n","# iterations = 5000 # @param{type: \"integer\"} \n","\n","# for it in range(0, iterations + 1):\n","#     # Step 1: calculate loss and gradients\n","#     loss, grads = compute_loss_and_grads(content_image_tensor, style_image_tensor, combination_image_tensor)\n","#     # Step 2: apply gradients\n","#     optimizer.apply_gradients([(grads, combination_image_tensor)])\n","    \n","\n","#     # Display images\n","#     # display.clear_output()  # This line clears output between iterations\n","#     if it % 500 == 0:\n","#       print(\"Iteration %d: loss=%.2f\" % (it, loss))\n","#       display_images(content_image, style_image, deprocess_image(combination_image_tensor))\n","\n","#     # Save image and/or model\n","#     if it==5000:\n","#       save(it, combination_image_tensor, save_image=False, save_model=True)"]},{"cell_type":"markdown","metadata":{"id":"KwQA-xasMweD"},"source":["## Generation Code:"]},{"cell_type":"code","source":["#@title * The project has been made open source on github. We can download the saved model directly from the github URL.\n"],"metadata":{"cellView":"form","id":"R9dGJiMTShkQ","executionInfo":{"status":"ok","timestamp":1650463821228,"user_tz":-60,"elapsed":9,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["#@title Download Saved Model\n","!wget \"https://github.com/Shao210934641/download/raw/main/models.zip\" -P \"/content/models_0\"\n","!unzip \"/content/models_0/models.zip\" -d \"/content/models\"\n","\n","!wget \"https://github.com/Shao210934641/download/raw/main/images.zip\" -P \"/content/images_0\"\n","!unzip \"/content/images_0/images.zip\" -d \"/content/images\"\n","display.clear_output()"],"metadata":{"cellView":"form","id":"Vkci-JE_QEM8","executionInfo":{"status":"ok","timestamp":1650463832921,"user_tz":-60,"elapsed":11701,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","execution_count":21,"metadata":{"id":"-l9OrGkOk5Ny","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1yvplgi___0E3sWv_zqxVz8hgpClNEMTg"},"executionInfo":{"status":"ok","timestamp":1650463883233,"user_tz":-60,"elapsed":50315,"user":{"displayName":"JIAHUI SHAO","userId":"00662894275701319123"}},"outputId":"8419ca97-bb0f-4c31-c9d7-51ccbee6a7c6"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#@title Load model and generate images\n","\n","full_path_g = '/content/models/gen.tf'\n","full_path_d = '/content/models/disc.tf'\n","gen2 = tf.keras.models.load_model(full_path_g)\n","disc2 = tf.keras.models.load_model(full_path_d)\n","\n","# Put together GAN model with the loaded networks\n","model = GAN(\n","    gen = gen2,\n","    disc = disc2,\n","    gen_optimizer = gen_optimizer,\n","    disc_optimizer = disc_optimizer,\n","    seed_size = seed_size\n",")\n","\n","# Generate some images!\n","samples = model.predict(tf.random.normal(shape=(10, 1, 1, seed_size)))\n","\n","# Save some of theses images for later style transfer\n","for i in range(9):\n","  plt.subplot(3,3,i+1)\n","  plt.imshow(samples[i,:,:,:])\n","  plt.axis('off')\n","  plt.subplots_adjust(wspace=0, hspace=0)\n","# plt.savefig('/content/gdrive/My Drive/ECS7022P/media/images/content.png')  # store the images \n","plt.savefig('/content/content.png')\n","plt.show()  # display the images\n","display.clear_output()\n","print('GAN: ')\n","show_images(samples)\n","print(' ')\n","print(' ')\n","print('Style Transfer: ')\n","\n","# Load into 2 variables named style_image and content_image.\n","content_image = keras.preprocessing.image.load_img('/content/content.png')\n","style_image = keras.preprocessing.image.load_img('/content/images/images/style1.png')\n","\n","content_image_np = keras.preprocessing.image.img_to_array(content_image)\n","style_image_np = keras.preprocessing.image.img_to_array(style_image)\n","\n","# Fast Neural Style Transfer with TF-Hub\n","hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n","\n","# Using the numpy arrays representing our images, with 1 batch dimension added, and normalized\n","c_img = np.expand_dims(content_image_np, axis=0)/255 \n","s_img = np.expand_dims(style_image_np, axis=0)/255 \n","\n","# Artefact 01\n","stylized_image = hub_model(tf.constant(c_img), tf.constant(s_img))[0]\n","display_images(c_img[0], s_img[0], stylized_image[0], num='01')\n","\n","# Artefact 02\n","style_image = keras.preprocessing.image.load_img('/content/images/images/style2.png')\n","style_image_np = keras.preprocessing.image.img_to_array(style_image)\n","s_img = np.expand_dims(style_image_np, axis=0)/255\n","stylized_image = hub_model(tf.constant(c_img), tf.constant(s_img))[0]\n","display_images(c_img[0], s_img[0], stylized_image[0], num='02')\n","\n","# Artefact 03\n","style_image = keras.preprocessing.image.load_img('/content/images/images/style3.png')\n","style_image_np = keras.preprocessing.image.img_to_array(style_image)\n","s_img = np.expand_dims(style_image_np, axis=0)/255 \n","stylized_image = hub_model(tf.constant(c_img), tf.constant(s_img))[0]\n","display_images(c_img[0], s_img[0], stylized_image[0], num='03')\n","\n","\n","# Artefact 04\n","style_image = keras.preprocessing.image.load_img('/content/images/images/style4.png')\n","style_image_np = keras.preprocessing.image.img_to_array(style_image)\n","s_img = np.expand_dims(style_image_np, axis=0)/255 \n","stylized_image = hub_model(tf.constant(c_img), tf.constant(s_img))[0]\n","display_images(c_img[0], s_img[0], stylized_image[0], num='04')\n","\n","\n","# Artefact 05\n","style_image = keras.preprocessing.image.load_img('/content/images/images/style5.png')\n","style_image_np = keras.preprocessing.image.img_to_array(style_image)\n","s_img = np.expand_dims(style_image_np, axis=0)/255 \n","stylized_image = hub_model(tf.constant(c_img), tf.constant(s_img))[0]\n","display_images(c_img[0], s_img[0], stylized_image[0], num='05')\n","\n","\n","# Artefact 06\n","style_image = keras.preprocessing.image.load_img('/content/images/images/style6.png')\n","style_image_np = keras.preprocessing.image.img_to_array(style_image)\n","s_img = np.expand_dims(style_image_np, axis=0)/255 \n","stylized_image = hub_model(tf.constant(c_img), tf.constant(s_img))[0]\n","display_images(c_img[0], s_img[0], stylized_image[0], num='06')\n","\n","\n","# Artefact 07\n","style_image = keras.preprocessing.image.load_img('/content/images/images/style7.png')\n","style_image_np = keras.preprocessing.image.img_to_array(style_image)\n","s_img = np.expand_dims(style_image_np, axis=0)/255 \n","stylized_image = hub_model(tf.constant(c_img), tf.constant(s_img))[0]\n","display_images(c_img[0], s_img[0], stylized_image[0], num='07')\n","\n","\n","# Artefact 08\n","style_image = keras.preprocessing.image.load_img('/content/images/images/style8.png')\n","style_image_np = keras.preprocessing.image.img_to_array(style_image)\n","s_img = np.expand_dims(style_image_np, axis=0)/255 \n","stylized_image = hub_model(tf.constant(c_img), tf.constant(s_img))[0]\n","display_images(c_img[0], s_img[0], stylized_image[0], num='08')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"210934641.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}